# -*- coding: utf-8 -*-
"""DataNeuron Submission.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iVJsWxE16VUrQGvnveJGakIdnSLPfBK6

Business Problem:
  Finding the Similarity between two sentences in terms of meaning

Import Libraries
"""
print("Importing Libraries")
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import re
import string
import nltk
from wordcloud import WordCloud
from sklearn.feature_extraction.text import TfidfVectorizer
from nltk.tokenize.treebank import TreebankWordDetokenizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.pipeline import Pipeline
import spacy
from collections import Counter
nlp = spacy.load('en_core_web_sm')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('omw-1.4')
nltk.download('punkt')
print("Libraries imported")

"""Import CSV file"""
print("Fetching Dataframe")
data=pd.read_csv('DataNeuron_Text_Similarity.csv')
data.head(1)
copydata=data.copy()
print("Dataframe fetched")
"""Check for missing and duplicates"""

copydata.isnull().sum()

# print(copydata.head())

"""Data Pre-processing"""
print("Data Pre-processing started")
def remove_punc(copydata):
  pattern = r'[' + string.punctuation + ']'
  copydata['text1']=data['text1'].map(lambda m:re.sub(pattern," ",m))
  copydata['text2']=data['text2'].map(lambda m:re.sub(pattern," ",m))
  return copydata


def lower(copydata):
  copydata['text1']=copydata['text1'].map(lambda m:m.lower())
  copydata['text2']=copydata['text2'].map(lambda m:m.lower())
  return copydata


def tokenization(text):
  tokens = re.split(' ',text)
  return tokens

def token(copydata):
  copydata['text1']= copydata['text1'].apply(lambda x: tokenization(x))
  copydata['text2']= copydata['text2'].apply(lambda x: tokenization(x))
  return copydata


sw=nltk.corpus.stopwords.words('english')

def remove_SW(copydata):
  copydata['text1']=copydata['text1'].apply(lambda x: [item for item in x if item not in sw])
  copydata['text2']=copydata['text2'].apply(lambda x: [item for item in x if item not in sw])
  return copydata


def remove_digits(copydata):
  copydata['text1']=copydata['text1'].apply(lambda x: [item for item in x if not item.isdigit()])
  copydata['text2']=copydata['text2'].apply(lambda x: [item for item in x if not item.isdigit()])
  return copydata

def remove_empty_tokens(copydata):
  copydata['text1']=copydata['text1'].apply(lambda x: [item for item in x if item !=''])
  copydata['text2']=copydata['text2'].apply(lambda x: [item for item in x if item !=''])
  return copydata


def remove_single_letters(copydata):
  copydata['text1']=copydata['text1'].apply(lambda x: [item for item in x if len(item) > 1])
  copydata['text2']=copydata['text2'].apply(lambda x: [item for item in x if len(item) > 1])
  return copydata


def detoken(copydata):
  copydata['text1']= copydata['text1'].apply(lambda x: TreebankWordDetokenizer().detokenize(x))
  copydata['text2']= copydata['text2'].apply(lambda x: TreebankWordDetokenizer().detokenize(x))
  return copydata

def replace_spaces(x,space,second):
  result = x.replace(space, second)
  return result

def remove_space(copydata):
  copydata['text1']= copydata['text1'].apply(lambda x: replace_spaces(x,'  ',' '))
  copydata['text2']= copydata['text2'].apply(lambda x: replace_spaces(x,'  ',' '))
  return copydata

def similarity_fn():
  for i in range(len(copydata)):
    doc1=copydata['text1'][i]
    doc2=copydata['text2'][i]
    docs=(doc1,doc2)
    tfidf_matrix = tfidf_vectorizer.fit_transform(docs)
    cosine_sim = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])
    similarity.append(cosine_sim)
  return similarity

"""Pre-processing Pipeline"""

copydata=copydata.pipe(remove_punc).pipe(token).pipe(remove_SW).pipe(remove_digits).pipe(remove_empty_tokens).pipe(remove_single_letters)

print("After Pre-processing")
# print(copydata.head())


def stack_concat():
  stack1=copydata['text1'].apply(pd.Series).stack()
  stack2=copydata['text2'].apply(pd.Series).stack()
  temp=pd.concat([stack1,stack2])
  return temp
ct=stack_concat()
stacked=ct.str.cat(sep=' ')

word_cloud = WordCloud(width=800, height=400,colormap="Dark2",collocations=False,).generate(stacked)
plt.figure( figsize=(20,10) )
plt.imshow(word_cloud)
plt.axis("off")

tfidf_vectorizer = TfidfVectorizer()
copydata.pipe(detoken).pipe(remove_space)
similarity=[]
similarity=similarity_fn()
data_tf=copydata.copy()
data_tf['Tf-idf Similarity']=similarity


# print("Calling function")
def siml(text1, text2):
  d = {'text1': [text1], 'text2': [text2]}
  df = pd.DataFrame(data=d)

  doc1=df['text1'][0]
  doc2=df['text2'][0]
  docs=(doc1,doc2)
  tfidf_matrix = tfidf_vectorizer.fit_transform(docs)
  cosine_sim = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])

  return cosine_sim
